{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "en_to_fr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGnTw9hlC+B33Pj2cgDps+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yahyasungur/nlp_dl_ml_projects/blob/master/en_to_fr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrQzzowdAWBx"
      },
      "source": [
        "%load_ext autoreload\n",
        "#%aimport helper, tests\n",
        "%autoreload 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wicg-IZYAtr0"
      },
      "source": [
        "import collections\n",
        "\n",
        "import helper\n",
        "import numpy as np\n",
        "#import project_tests as tests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0J8IVZjAwei"
      },
      "source": [
        "def load_data(path):\n",
        "\n",
        "    input_file = os.path.join(path)\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    return data.split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZcMKZWGAwg6",
        "outputId": "a04932ce-e77e-4875-8e36-03a6ccc4fb35"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 4435678779321353526\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR084a9FAwlX"
      },
      "source": [
        "english_sentences = load_data('small_vocab_en')\n",
        "french_sentences = load_data('small_vocab_fr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyLPNvyrAwoB",
        "outputId": "886f8c3f-df22-49c9-a71e-1d0f2a3885bf"
      },
      "source": [
        "for i in range(5):\n",
        "  print(\"en:  \",english_sentences[i+1])\n",
        "  print(\"fr:  \",french_sentences[i+1],'\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en:   the united states is usually chilly during july , and it is usually freezing in november .\n",
            "fr:   les états-unis est généralement froid en juillet , et il gèle habituellement en novembre . \n",
            "\n",
            "en:   california is usually quiet during march , and it is usually hot in june .\n",
            "fr:   california est généralement calme en mars , et il est généralement chaud en juin . \n",
            "\n",
            "en:   the united states is sometimes mild during june , and it is cold in september .\n",
            "fr:   les états-unis est parfois légère en juin , et il fait froid en septembre . \n",
            "\n",
            "en:   your least liked fruit is the grape , but my least liked is the apple .\n",
            "fr:   votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme . \n",
            "\n",
            "en:   his favorite fruit is the orange , but my favorite is the grape .\n",
            "fr:   son fruit préféré est l'orange , mais mon préféré est le raisin . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at_1_qm9AwrV"
      },
      "source": [
        "#Tokenization\n",
        "\n",
        "def tokenize(x):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(x)\n",
        "    return tokenizer.texts_to_sequences(x), tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FX1U2-zAwtG"
      },
      "source": [
        "#Padding\n",
        "\n",
        "def pad(x, length=None):\n",
        "    return pad_sequences(x, maxlen=length, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA-6pD2sA6HM"
      },
      "source": [
        "def preprocess(x, y):\n",
        "\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
        "\n",
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(english_sentences, french_sentences)\n",
        "    \n",
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F__V0_QTA8e2"
      },
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knVe1skhBNcT"
      },
      "source": [
        "#Custom model (Final version)\n",
        "\n",
        "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "\n",
        "  learning_rate = 0.003\n",
        "\n",
        "  model = Sequential()\n",
        "  \n",
        "  #embedding\n",
        "  model.add(Embedding(english_vocab_size, 128, input_length=input_shape[1], input_shape= input_shape[1:]))\n",
        "  \n",
        "  #encoder\n",
        "  model.add(Bidirectional(GRU(128)))\n",
        "  model.add(RepeatVector(output_sequence_length))\n",
        "\n",
        "  #decoder\n",
        "  model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
        "  model.add(TimeDistributed(Dense(512, activation='relu')))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax')))\n",
        "  \n",
        "  #compile\n",
        "  model.compile(loss= sparse_categorical_crossentropy, optimizer= Adam(learning_rate), metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smc6kHQrBFn1"
      },
      "source": [
        "#Reshape the input\n",
        "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrB0x7BmBPep",
        "outputId": "a8975dae-54de-441a-8f1f-9f5fffa2a97c"
      },
      "source": [
        "model = model_final(preproc_english_sentences.shape, preproc_french_sentences.shape[1], len(english_tokenizer.word_index)+1, len(french_tokenizer.word_index)+1)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 15, 128)           25600     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               198144    \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 21, 256)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 21, 256)           296448    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 21, 512)           131584    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 21, 512)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 21, 345)           176985    \n",
            "=================================================================\n",
            "Total params: 828,761\n",
            "Trainable params: 828,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEGSpC41BQ80",
        "outputId": "2c1fc787-b42e-417f-a31c-975c00b226d2"
      },
      "source": [
        "#Train\n",
        "model.fit(preproc_english_sentences, preproc_french_sentences, batch_size=1024, epochs=25, validation_split=0.2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "108/108 [==============================] - 302s 3s/step - loss: 2.5895 - accuracy: 0.4679 - val_loss: 1.6722 - val_accuracy: 0.5792\n",
            "Epoch 2/25\n",
            "108/108 [==============================] - 294s 3s/step - loss: 1.5210 - accuracy: 0.6025 - val_loss: 1.2783 - val_accuracy: 0.6534\n",
            "Epoch 3/25\n",
            "108/108 [==============================] - 292s 3s/step - loss: 1.2147 - accuracy: 0.6641 - val_loss: 1.0185 - val_accuracy: 0.7067\n",
            "Epoch 4/25\n",
            "108/108 [==============================] - 292s 3s/step - loss: 1.0092 - accuracy: 0.7083 - val_loss: 0.8594 - val_accuracy: 0.7437\n",
            "Epoch 5/25\n",
            "108/108 [==============================] - 292s 3s/step - loss: 0.8989 - accuracy: 0.7299 - val_loss: 0.8709 - val_accuracy: 0.7327\n",
            "Epoch 6/25\n",
            "108/108 [==============================] - 291s 3s/step - loss: 0.7646 - accuracy: 0.7628 - val_loss: 0.6134 - val_accuracy: 0.8070\n",
            "Epoch 7/25\n",
            "108/108 [==============================] - 293s 3s/step - loss: 0.7766 - accuracy: 0.7636 - val_loss: 0.7839 - val_accuracy: 0.7590\n",
            "Epoch 8/25\n",
            "108/108 [==============================] - 292s 3s/step - loss: 0.6925 - accuracy: 0.7837 - val_loss: 0.4895 - val_accuracy: 0.8489\n",
            "Epoch 9/25\n",
            "108/108 [==============================] - 294s 3s/step - loss: 0.5285 - accuracy: 0.8323 - val_loss: 0.4170 - val_accuracy: 0.8698\n",
            "Epoch 10/25\n",
            "108/108 [==============================] - 294s 3s/step - loss: 0.4457 - accuracy: 0.8587 - val_loss: 0.3249 - val_accuracy: 0.8997\n",
            "Epoch 11/25\n",
            "108/108 [==============================] - 294s 3s/step - loss: 0.3766 - accuracy: 0.8818 - val_loss: 0.2739 - val_accuracy: 0.9211\n",
            "Epoch 12/25\n",
            "108/108 [==============================] - 293s 3s/step - loss: 0.3139 - accuracy: 0.9051 - val_loss: 0.2153 - val_accuracy: 0.9398\n",
            "Epoch 13/25\n",
            "108/108 [==============================] - 292s 3s/step - loss: 0.2753 - accuracy: 0.9180 - val_loss: 0.1864 - val_accuracy: 0.9478\n",
            "Epoch 14/25\n",
            "108/108 [==============================] - 292s 3s/step - loss: 0.2295 - accuracy: 0.9324 - val_loss: 0.1674 - val_accuracy: 0.9533\n",
            "Epoch 15/25\n",
            "108/108 [==============================] - 294s 3s/step - loss: 0.2212 - accuracy: 0.9341 - val_loss: 0.1498 - val_accuracy: 0.9577\n",
            "Epoch 16/25\n",
            "108/108 [==============================] - 294s 3s/step - loss: 0.1841 - accuracy: 0.9459 - val_loss: 0.1349 - val_accuracy: 0.9609\n",
            "Epoch 17/25\n",
            "108/108 [==============================] - 292s 3s/step - loss: 0.1700 - accuracy: 0.9499 - val_loss: 0.1523 - val_accuracy: 0.9564\n",
            "Epoch 18/25\n",
            "108/108 [==============================] - 293s 3s/step - loss: 0.2645 - accuracy: 0.9212 - val_loss: 0.1291 - val_accuracy: 0.9638\n",
            "Epoch 19/25\n",
            "108/108 [==============================] - 293s 3s/step - loss: 0.1535 - accuracy: 0.9548 - val_loss: 0.1149 - val_accuracy: 0.9678\n",
            "Epoch 20/25\n",
            "108/108 [==============================] - 292s 3s/step - loss: 0.1327 - accuracy: 0.9608 - val_loss: 0.1035 - val_accuracy: 0.9703\n",
            "Epoch 21/25\n",
            "108/108 [==============================] - 293s 3s/step - loss: 0.1299 - accuracy: 0.9614 - val_loss: 0.1030 - val_accuracy: 0.9704\n",
            "Epoch 22/25\n",
            "108/108 [==============================] - 291s 3s/step - loss: 0.1164 - accuracy: 0.9653 - val_loss: 0.0942 - val_accuracy: 0.9736\n",
            "Epoch 23/25\n",
            "108/108 [==============================] - 292s 3s/step - loss: 0.1099 - accuracy: 0.9671 - val_loss: 0.0944 - val_accuracy: 0.9741\n",
            "Epoch 24/25\n",
            "108/108 [==============================] - 292s 3s/step - loss: 0.1050 - accuracy: 0.9684 - val_loss: 0.0905 - val_accuracy: 0.9753\n",
            "Epoch 25/25\n",
            "108/108 [==============================] - 291s 3s/step - loss: 0.0981 - accuracy: 0.9705 - val_loss: 0.0874 - val_accuracy: 0.9747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3fbbf9d50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT21Z-LpBw5X"
      },
      "source": [
        "x = preproc_english_sentences\n",
        "y = preproc_french_sentences\n",
        "x_tk = english_tokenizer\n",
        "y_tk = french_tokenizer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjD_woggBTf8"
      },
      "source": [
        "y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
        "y_id_to_word[0] = '<PAD>'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbI8flT-BWzf"
      },
      "source": [
        "def translate(sent):\n",
        "  sentence = sent\n",
        "  sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
        "  sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
        "  sentences = np.array([sentence[0], x[0]])\n",
        "  predictions = model.predict(sentences, len(sentences))\n",
        "  output = ' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]])\n",
        "  return output"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05jw_6IZBZg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c996a2cc-65ba-4ad7-d2df-4c33309d79ab"
      },
      "source": [
        "print(translate('he saw a old yellow truck'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "il a vu un vieux camion jaune <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ]
        }
      ]
    }
  ]
}