{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vocabulary and Matching.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNk5o3YUdXoDC7sQoLrAsB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yahyasungur/nlp_dl_ml_projects/blob/master/Vocabulary_and_Matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxDOwf-d8aVL"
      },
      "source": [
        "# Rule - Based Matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okjkGHdI3U7Q"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9lzX4Lc8zOx"
      },
      "source": [
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMUZ8BDa9Zqj"
      },
      "source": [
        "## Creating Patterns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvA0qocZ9eYR"
      },
      "source": [
        "# create a list, and inside that list add series of dictionaries\n",
        "\n",
        "# Hello World can appear in the following ways,\n",
        "# 1) Hello World  hello world Hello WORLD\n",
        "# 2) Hello-World\n",
        "\n",
        "pattern_1 = [{'LOWER': 'hi'}, {'LOWER': 'yahya'}]\n",
        "pattern_2 = [{'LOWER': 'hi'}, {'IS_PUNCT': True}, {'LOWER': 'yahya'}]\n",
        "\n",
        "# 'LOWER', 'IS_PUNCT' are the attributes\n",
        "# they has to be written in  that way only"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H5FlP-l98JV"
      },
      "source": [
        "# Add patterns to matcher object\n",
        "\n",
        "# Add a match rule to matcher, A match rule consists of,\n",
        "# 1) An ID key\n",
        "# 2) an on_match callback\n",
        "# 3) one or more pattern\n",
        "\n",
        "matcher.add('Hi Yahya',None,pattern_1,pattern_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VVctWf4-I-J"
      },
      "source": [
        "# create document\n",
        "\n",
        "doc = nlp(\"Hi Yahya, how are you ? I'm dying to see you these days. I hope to see you soon and I can say hi! to you.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8h9pjTt-5kW",
        "outputId": "ec9add5b-d66d-4359-c0b3-81fbfffedd3a"
      },
      "source": [
        "doc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Hi Yahya, how are you ? I'm dying to see you these days. I hope to see you soon and I can say hi! to you."
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-30Dvqjk-_L5"
      },
      "source": [
        "## Finding the matches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE-SW45S-9Od",
        "outputId": "550f4f73-2711-4044-bc36-c49334cc0eaa"
      },
      "source": [
        "find_matches = matcher(doc) # passin doc to matcher object and store this in a variable\n",
        "print(find_matches)\n",
        "\n",
        "# it returns output list of tuples\n",
        "# string ID, index start and index end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(2536870178538414864, 0, 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmpAQpvPBLd9",
        "outputId": "675796bd-06e3-4b10-9d6e-7968fff3e9ba"
      },
      "source": [
        "# define a function to find the matches\n",
        "\n",
        "for match_id, start, end in find_matches:\n",
        "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
        "    span = doc[start:end]                    # get the matched span\n",
        "    print(match_id, string_id, start, end, span.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2536870178538414864 Hi Yahya 0 2 Hi Yahya\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cuGuroUBV-8"
      },
      "source": [
        "# Removing the matches\n",
        "matcher.remove('Hello World')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzdNzlNHBtNB"
      },
      "source": [
        "## Setting pattern options and quantifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARd0266GBz88"
      },
      "source": [
        "# Redefine the patterns:\n",
        "pattern_3 = [{'LOWER': 'hi'}, {'LOWER': 'yahya'}]\n",
        "pattern_4 = [{'LOWER': 'hi'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'yahya'}]\n",
        "# 'OP':'*' ----> Thisis going to allow this pattern to match zero or more times for any punctuation\n",
        "\n",
        "# Add the new set of patterns to the 'Hellow World' matcher:\n",
        "matcher.add('Hello World', None, pattern_3, pattern_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOVnlod7B9Bl"
      },
      "source": [
        "doc_2 = nlp(\"You can print Hi Yahya or hi yahya or Hi-Yahya\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqLUQmf-CIpQ",
        "outputId": "59c98d43-8f7e-49cf-c5cb-e476d9a744b5"
      },
      "source": [
        "find_matches = matcher(doc_2)\n",
        "print(find_matches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(2536870178538414864, 3, 5), (8585552006568828647, 3, 5), (2536870178538414864, 6, 8), (8585552006568828647, 6, 8), (2536870178538414864, 9, 12), (8585552006568828647, 9, 12)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCapXx9qIfdU"
      },
      "source": [
        "# Phrase Matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA8m-QlHIkb2"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agoHL9lyJyUD"
      },
      "source": [
        "#import the PhraseMatcher library\n",
        "from spacy.matcher import PhraseMatcher\n",
        "matcher = PhraseMatcher(nlp.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0IiWJgSJ-0o"
      },
      "source": [
        "phrase_list = [\"Barack Obama\",\"Angela Merkel\",\"Washington, D.C.\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGLp5SxNKLeh"
      },
      "source": [
        "# Convert each phrase to the document object\n",
        "phrase_patterns = [nlp(text) for text in phrase_list] # to do that we are using list comprehension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNljWfkmKdAd",
        "outputId": "b4f4b274-c71a-432e-e701-e77d8ec0ec26"
      },
      "source": [
        "phrase_patterns # phrase objects are not strings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Barack Obama, Angela Merkel, Washington, D.C.]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzgXq82WKi5f",
        "outputId": "c1fde15c-2a47-464e-cb22-8f4386d95ddc"
      },
      "source": [
        "type(phrase_patterns[1])\n",
        "# they are the spacy docs\n",
        "# thats why we don't have any quotes there"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBJNjXrCKrXM"
      },
      "source": [
        "# pass each doc object into the matcher\n",
        "matcher.add(\"TerminologyList\", None, *phrase_patterns)\n",
        "# thats we have to add asterisk mark before phrase_pattern"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8TYLRuYKvGb"
      },
      "source": [
        "doc_3 = nlp(\"German Chancellor Angela Merkel and US President Barack Obama \" \"converse in the Oval Office inside the White House in Washington, D.C.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPkP_Y-cK-25",
        "outputId": "11bb6d78-39f3-4e19-ed9a-0966a9fbe71b"
      },
      "source": [
        "find_matches = matcher(doc_3) # passin doc to matcher object and store this in a variable \n",
        "print(find_matches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(3766102292120407359, 2, 4), (3766102292120407359, 7, 9), (3766102292120407359, 19, 22)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ruofj80dLCss",
        "outputId": "5e748fed-8414-4928-8b7d-0490e10ea317"
      },
      "source": [
        "# define a function to find the matches\n",
        "\n",
        "for match_id, start, end in find_matches:\n",
        "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
        "    span = doc_3[start:end]                    # get the matched span\n",
        "    print(match_id, string_id, start, end, span.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3766102292120407359 TerminologyList 2 4 Angela Merkel\n",
            "3766102292120407359 TerminologyList 7 9 Barack Obama\n",
            "3766102292120407359 TerminologyList 19 22 Washington, D.C.\n"
          ]
        }
      ]
    }
  ]
}